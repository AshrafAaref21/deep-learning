{"cells":[{"cell_type":"markdown","metadata":{"id":"-x9nhu3Lj98o"},"source":["# Food Vision Model\n","> Prediciting 101 different Classes"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":718,"status":"ok","timestamp":1699449174566,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"},"user_tz":-120},"id":"PrbVhFJjmzKf","outputId":"4f6c7f08-9ec0-4b7e-b0d2-077c0ece1fca"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-11-08 13:11:42--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10246 (10K) [text/plain]\n","Saving to: ‘helper_functions.py.1’\n","\n","\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n","\n","2023-11-08 13:11:42 (82.9 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6634,"status":"ok","timestamp":1699449183062,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"},"user_tz":-120},"id":"Mfq1a01WnJrp"},"outputs":[],"source":["from helper_functions import *"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":771,"status":"ok","timestamp":1699449183831,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"},"user_tz":-120},"id":"LigwWZFinV0d"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1905,"status":"ok","timestamp":1699449185733,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"},"user_tz":-120},"id":"SlCFHKAooQ_i","outputId":"f1457991-cec2-4cf6-e225-a62a88661eb4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['abstract_reasoning', 'accentdb', 'aeslc', 'aflw2k3d', 'ag_news_subset'],\n"," True)"]},"metadata":{},"execution_count":5}],"source":["data_sets_list = tfds.list_builders()\n","\n","(data_sets_list[:5]),('food101' in data_sets_list)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"F7i_TW-XoWls","executionInfo":{"status":"ok","timestamp":1699449187872,"user_tz":-120,"elapsed":2141,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"}}},"outputs":[],"source":["(train_data,test_data), ds_info = tfds.load(name='food101',\n","                                            split=['train','validation'],\n","                                            shuffle_files=True,\n","                                            as_supervised=True,\n","                                            with_info=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xj3X36GmzYdz","executionInfo":{"status":"ok","timestamp":1699449187872,"user_tz":-120,"elapsed":7,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"}},"outputId":"acce6f0e-198a-489b-f51a-3f3a052e4499"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":7}],"source":["train_data"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"9Vp4SCqqpjTl","executionInfo":{"status":"ok","timestamp":1699449190541,"user_tz":-120,"elapsed":269,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"}}},"outputs":[],"source":["def preprocess_img(image, label, img_shape=224):\n","  image = tf.image.resize(image,[img_shape,img_shape])\n","  return tf.cast(image,tf.float32), label"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"8QfVcMDhBPmE","executionInfo":{"status":"ok","timestamp":1699448920519,"user_tz":-120,"elapsed":9,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{"id":"VMb6rlNtxMCS","executionInfo":{"status":"ok","timestamp":1699449192382,"user_tz":-120,"elapsed":279,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"}}},"outputs":[],"source":["train_data = train_data.map(map_func=preprocess_img,\n","                            num_parallel_calls= tf.data.AUTOTUNE)\n","\n","train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n","\n","\n","\n","test_data = test_data.map(map_func=preprocess_img,\n","                            num_parallel_calls= tf.data.AUTOTUNE)\n","\n","test_data = test_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ETU6OrNjByVo","executionInfo":{"status":"ok","timestamp":1699448920519,"user_tz":-120,"elapsed":8,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"}},"outputId":"3e63e177-3ca1-43da-f5ef-c325ee56c489"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":9}],"source":["train_data"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"fwBKs60aB3k_","executionInfo":{"status":"ok","timestamp":1699449718880,"user_tz":-120,"elapsed":676,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"}}},"outputs":[],"source":["check_point = 'model_checkpoints/cp.ckpt'\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","    check_point,\n","    monitor='val_acc',\n","    save_best_only=True,\n","    save_weights_only=True,\n","    verbose=0\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"HnYiDZaMeXfA","executionInfo":{"status":"ok","timestamp":1699449195970,"user_tz":-120,"elapsed":403,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"}}},"outputs":[],"source":["from tensorflow.keras import mixed_precision\n","mixed_precision.set_global_policy('mixed_float16')"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"5DVVKU4cFfRo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699450551797,"user_tz":-120,"elapsed":773390,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"}},"outputId":"f0129a85-208f-4b7a-a362-05b43263caf1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n","71686520/71686520 [==============================] - 0s 0us/step\n","Saving TensorBoard log files to: FOOD_VISION_101/Efficient_net/20231108-132153\n","Epoch 1/3\n","2368/2368 [==============================] - ETA: 0s - loss: 1.7852 - accuracy: 0.5575"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2368/2368 [==============================] - 256s 102ms/step - loss: 1.7852 - accuracy: 0.5575 - val_loss: 1.2544 - val_accuracy: 0.6703\n","Epoch 2/3\n","2367/2368 [============================>.] - ETA: 0s - loss: 1.3076 - accuracy: 0.6581"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2368/2368 [==============================] - 250s 104ms/step - loss: 1.3077 - accuracy: 0.6581 - val_loss: 1.1473 - val_accuracy: 0.6888\n","Epoch 3/3\n","2367/2368 [============================>.] - ETA: 0s - loss: 1.1618 - accuracy: 0.6937"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2368/2368 [==============================] - 248s 104ms/step - loss: 1.1618 - accuracy: 0.6937 - val_loss: 1.1122 - val_accuracy: 0.7071\n"]}],"source":["from tensorflow.keras import layers\n","from tensorflow.keras import preprocessing\n","\n","base_model = tf.keras.applications.EfficientNetB4(include_top=False)\n","base_model.trainable = False\n","\n","inputs = layers.Input(shape=(224, 224, 3),\n","                      name = 'input_layer')\n","\n","x = base_model(inputs,\n","               training=False\n","               )\n","\n","x = layers.GlobalAveragePooling2D(name='avg_pooling')(x)\n","\n","outputs = layers.Dense(101,\n","                       activation= 'softmax',\n","                       dtype=tf.float32)(x)\n","\n","model = tf.keras.Model(inputs,outputs)\n","\n","model.compile(\n","    loss= tf.keras.losses.SparseCategoricalCrossentropy(),\n","    optimizer= tf.keras.optimizers.Adam(),\n","    metrics=['accuracy']\n","    )\n","\n","history = model.fit(\n","    train_data,\n","    epochs=3,\n","    steps_per_epoch=len(train_data),\n","    validation_data=test_data,\n","    validation_steps=int(0.15*len(test_data)),\n","    callbacks=[model_checkpoint,\n","               create_tensorboard_callback(\n","                  'FOOD_VISION_101',\n","                  'Efficient_net'\n","               )]\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"c_Us8s8weo6j","executionInfo":{"status":"ok","timestamp":1699450630207,"user_tz":-120,"elapsed":8,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"}}},"outputs":[],"source":["for layer in base_model.layers[-10:]:\n","  layer.trainable = True"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1699450551798,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"},"user_tz":-120},"id":"SPvq-ZrtworY","outputId":"57e2e180-fcff-4153-eff7-0091a0100fcd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n","                                                                 \n"," efficientnetb4 (Functional  (None, None, None, 1792   17673823  \n"," )                           )                                   \n","                                                                 \n"," avg_pooling (GlobalAverage  (None, 1792)              0         \n"," Pooling2D)                                                      \n","                                                                 \n"," dense_3 (Dense)             (None, 101)               181093    \n","                                                                 \n","=================================================================\n","Total params: 17854916 (68.11 MB)\n","Trainable params: 181093 (707.39 KB)\n","Non-trainable params: 17673823 (67.42 MB)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":515,"status":"ok","timestamp":1699450552303,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"},"user_tz":-120},"id":"HHBF3uvJji7V","outputId":"84b45ff7-6e71-4ad1-9de0-da54904c82c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["input_4 False\n","rescaling_6 False\n","normalization_3 False\n","rescaling_7 False\n","stem_conv_pad False\n","stem_conv False\n","stem_bn False\n","stem_activation False\n","block1a_dwconv False\n","block1a_bn False\n","block1a_activation False\n","block1a_se_squeeze False\n","block1a_se_reshape False\n","block1a_se_reduce False\n","block1a_se_expand False\n","block1a_se_excite False\n","block1a_project_conv False\n","block1a_project_bn False\n","block1b_dwconv False\n","block1b_bn False\n","block1b_activation False\n","block1b_se_squeeze False\n","block1b_se_reshape False\n","block1b_se_reduce False\n","block1b_se_expand False\n","block1b_se_excite False\n","block1b_project_conv False\n","block1b_project_bn False\n","block1b_drop False\n","block1b_add False\n","block2a_expand_conv False\n","block2a_expand_bn False\n","block2a_expand_activation False\n","block2a_dwconv_pad False\n","block2a_dwconv False\n","block2a_bn False\n","block2a_activation False\n","block2a_se_squeeze False\n","block2a_se_reshape False\n","block2a_se_reduce False\n","block2a_se_expand False\n","block2a_se_excite False\n","block2a_project_conv False\n","block2a_project_bn False\n","block2b_expand_conv False\n","block2b_expand_bn False\n","block2b_expand_activation False\n","block2b_dwconv False\n","block2b_bn False\n","block2b_activation False\n","block2b_se_squeeze False\n","block2b_se_reshape False\n","block2b_se_reduce False\n","block2b_se_expand False\n","block2b_se_excite False\n","block2b_project_conv False\n","block2b_project_bn False\n","block2b_drop False\n","block2b_add False\n","block2c_expand_conv False\n","block2c_expand_bn False\n","block2c_expand_activation False\n","block2c_dwconv False\n","block2c_bn False\n","block2c_activation False\n","block2c_se_squeeze False\n","block2c_se_reshape False\n","block2c_se_reduce False\n","block2c_se_expand False\n","block2c_se_excite False\n","block2c_project_conv False\n","block2c_project_bn False\n","block2c_drop False\n","block2c_add False\n","block2d_expand_conv False\n","block2d_expand_bn False\n","block2d_expand_activation False\n","block2d_dwconv False\n","block2d_bn False\n","block2d_activation False\n","block2d_se_squeeze False\n","block2d_se_reshape False\n","block2d_se_reduce False\n","block2d_se_expand False\n","block2d_se_excite False\n","block2d_project_conv False\n","block2d_project_bn False\n","block2d_drop False\n","block2d_add False\n","block3a_expand_conv False\n","block3a_expand_bn False\n","block3a_expand_activation False\n","block3a_dwconv_pad False\n","block3a_dwconv False\n","block3a_bn False\n","block3a_activation False\n","block3a_se_squeeze False\n","block3a_se_reshape False\n","block3a_se_reduce False\n","block3a_se_expand False\n","block3a_se_excite False\n","block3a_project_conv False\n","block3a_project_bn False\n","block3b_expand_conv False\n","block3b_expand_bn False\n","block3b_expand_activation False\n","block3b_dwconv False\n","block3b_bn False\n","block3b_activation False\n","block3b_se_squeeze False\n","block3b_se_reshape False\n","block3b_se_reduce False\n","block3b_se_expand False\n","block3b_se_excite False\n","block3b_project_conv False\n","block3b_project_bn False\n","block3b_drop False\n","block3b_add False\n","block3c_expand_conv False\n","block3c_expand_bn False\n","block3c_expand_activation False\n","block3c_dwconv False\n","block3c_bn False\n","block3c_activation False\n","block3c_se_squeeze False\n","block3c_se_reshape False\n","block3c_se_reduce False\n","block3c_se_expand False\n","block3c_se_excite False\n","block3c_project_conv False\n","block3c_project_bn False\n","block3c_drop False\n","block3c_add False\n","block3d_expand_conv False\n","block3d_expand_bn False\n","block3d_expand_activation False\n","block3d_dwconv False\n","block3d_bn False\n","block3d_activation False\n","block3d_se_squeeze False\n","block3d_se_reshape False\n","block3d_se_reduce False\n","block3d_se_expand False\n","block3d_se_excite False\n","block3d_project_conv False\n","block3d_project_bn False\n","block3d_drop False\n","block3d_add False\n","block4a_expand_conv False\n","block4a_expand_bn False\n","block4a_expand_activation False\n","block4a_dwconv_pad False\n","block4a_dwconv False\n","block4a_bn False\n","block4a_activation False\n","block4a_se_squeeze False\n","block4a_se_reshape False\n","block4a_se_reduce False\n","block4a_se_expand False\n","block4a_se_excite False\n","block4a_project_conv False\n","block4a_project_bn False\n","block4b_expand_conv False\n","block4b_expand_bn False\n","block4b_expand_activation False\n","block4b_dwconv False\n","block4b_bn False\n","block4b_activation False\n","block4b_se_squeeze False\n","block4b_se_reshape False\n","block4b_se_reduce False\n","block4b_se_expand False\n","block4b_se_excite False\n","block4b_project_conv False\n","block4b_project_bn False\n","block4b_drop False\n","block4b_add False\n","block4c_expand_conv False\n","block4c_expand_bn False\n","block4c_expand_activation False\n","block4c_dwconv False\n","block4c_bn False\n","block4c_activation False\n","block4c_se_squeeze False\n","block4c_se_reshape False\n","block4c_se_reduce False\n","block4c_se_expand False\n","block4c_se_excite False\n","block4c_project_conv False\n","block4c_project_bn False\n","block4c_drop False\n","block4c_add False\n","block4d_expand_conv False\n","block4d_expand_bn False\n","block4d_expand_activation False\n","block4d_dwconv False\n","block4d_bn False\n","block4d_activation False\n","block4d_se_squeeze False\n","block4d_se_reshape False\n","block4d_se_reduce False\n","block4d_se_expand False\n","block4d_se_excite False\n","block4d_project_conv False\n","block4d_project_bn False\n","block4d_drop False\n","block4d_add False\n","block4e_expand_conv False\n","block4e_expand_bn False\n","block4e_expand_activation False\n","block4e_dwconv False\n","block4e_bn False\n","block4e_activation False\n","block4e_se_squeeze False\n","block4e_se_reshape False\n","block4e_se_reduce False\n","block4e_se_expand False\n","block4e_se_excite False\n","block4e_project_conv False\n","block4e_project_bn False\n","block4e_drop False\n","block4e_add False\n","block4f_expand_conv False\n","block4f_expand_bn False\n","block4f_expand_activation False\n","block4f_dwconv False\n","block4f_bn False\n","block4f_activation False\n","block4f_se_squeeze False\n","block4f_se_reshape False\n","block4f_se_reduce False\n","block4f_se_expand False\n","block4f_se_excite False\n","block4f_project_conv False\n","block4f_project_bn False\n","block4f_drop False\n","block4f_add False\n","block5a_expand_conv False\n","block5a_expand_bn False\n","block5a_expand_activation False\n","block5a_dwconv False\n","block5a_bn False\n","block5a_activation False\n","block5a_se_squeeze False\n","block5a_se_reshape False\n","block5a_se_reduce False\n","block5a_se_expand False\n","block5a_se_excite False\n","block5a_project_conv False\n","block5a_project_bn False\n","block5b_expand_conv False\n","block5b_expand_bn False\n","block5b_expand_activation False\n","block5b_dwconv False\n","block5b_bn False\n","block5b_activation False\n","block5b_se_squeeze False\n","block5b_se_reshape False\n","block5b_se_reduce False\n","block5b_se_expand False\n","block5b_se_excite False\n","block5b_project_conv False\n","block5b_project_bn False\n","block5b_drop False\n","block5b_add False\n","block5c_expand_conv False\n","block5c_expand_bn False\n","block5c_expand_activation False\n","block5c_dwconv False\n","block5c_bn False\n","block5c_activation False\n","block5c_se_squeeze False\n","block5c_se_reshape False\n","block5c_se_reduce False\n","block5c_se_expand False\n","block5c_se_excite False\n","block5c_project_conv False\n","block5c_project_bn False\n","block5c_drop False\n","block5c_add False\n","block5d_expand_conv False\n","block5d_expand_bn False\n","block5d_expand_activation False\n","block5d_dwconv False\n","block5d_bn False\n","block5d_activation False\n","block5d_se_squeeze False\n","block5d_se_reshape False\n","block5d_se_reduce False\n","block5d_se_expand False\n","block5d_se_excite False\n","block5d_project_conv False\n","block5d_project_bn False\n","block5d_drop False\n","block5d_add False\n","block5e_expand_conv False\n","block5e_expand_bn False\n","block5e_expand_activation False\n","block5e_dwconv False\n","block5e_bn False\n","block5e_activation False\n","block5e_se_squeeze False\n","block5e_se_reshape False\n","block5e_se_reduce False\n","block5e_se_expand False\n","block5e_se_excite False\n","block5e_project_conv False\n","block5e_project_bn False\n","block5e_drop False\n","block5e_add False\n","block5f_expand_conv False\n","block5f_expand_bn False\n","block5f_expand_activation False\n","block5f_dwconv False\n","block5f_bn False\n","block5f_activation False\n","block5f_se_squeeze False\n","block5f_se_reshape False\n","block5f_se_reduce False\n","block5f_se_expand False\n","block5f_se_excite False\n","block5f_project_conv False\n","block5f_project_bn False\n","block5f_drop False\n","block5f_add False\n","block6a_expand_conv False\n","block6a_expand_bn False\n","block6a_expand_activation False\n","block6a_dwconv_pad False\n","block6a_dwconv False\n","block6a_bn False\n","block6a_activation False\n","block6a_se_squeeze False\n","block6a_se_reshape False\n","block6a_se_reduce False\n","block6a_se_expand False\n","block6a_se_excite False\n","block6a_project_conv False\n","block6a_project_bn False\n","block6b_expand_conv False\n","block6b_expand_bn False\n","block6b_expand_activation False\n","block6b_dwconv False\n","block6b_bn False\n","block6b_activation False\n","block6b_se_squeeze False\n","block6b_se_reshape False\n","block6b_se_reduce False\n","block6b_se_expand False\n","block6b_se_excite False\n","block6b_project_conv False\n","block6b_project_bn False\n","block6b_drop False\n","block6b_add False\n","block6c_expand_conv False\n","block6c_expand_bn False\n","block6c_expand_activation False\n","block6c_dwconv False\n","block6c_bn False\n","block6c_activation False\n","block6c_se_squeeze False\n","block6c_se_reshape False\n","block6c_se_reduce False\n","block6c_se_expand False\n","block6c_se_excite False\n","block6c_project_conv False\n","block6c_project_bn False\n","block6c_drop False\n","block6c_add False\n","block6d_expand_conv False\n","block6d_expand_bn False\n","block6d_expand_activation False\n","block6d_dwconv False\n","block6d_bn False\n","block6d_activation False\n","block6d_se_squeeze False\n","block6d_se_reshape False\n","block6d_se_reduce False\n","block6d_se_expand False\n","block6d_se_excite False\n","block6d_project_conv False\n","block6d_project_bn False\n","block6d_drop False\n","block6d_add False\n","block6e_expand_conv False\n","block6e_expand_bn False\n","block6e_expand_activation False\n","block6e_dwconv False\n","block6e_bn False\n","block6e_activation False\n","block6e_se_squeeze False\n","block6e_se_reshape False\n","block6e_se_reduce False\n","block6e_se_expand False\n","block6e_se_excite False\n","block6e_project_conv False\n","block6e_project_bn False\n","block6e_drop False\n","block6e_add False\n","block6f_expand_conv False\n","block6f_expand_bn False\n","block6f_expand_activation False\n","block6f_dwconv False\n","block6f_bn False\n","block6f_activation False\n","block6f_se_squeeze False\n","block6f_se_reshape False\n","block6f_se_reduce False\n","block6f_se_expand False\n","block6f_se_excite False\n","block6f_project_conv False\n","block6f_project_bn False\n","block6f_drop False\n","block6f_add False\n","block6g_expand_conv False\n","block6g_expand_bn False\n","block6g_expand_activation False\n","block6g_dwconv False\n","block6g_bn False\n","block6g_activation False\n","block6g_se_squeeze False\n","block6g_se_reshape False\n","block6g_se_reduce False\n","block6g_se_expand False\n","block6g_se_excite False\n","block6g_project_conv False\n","block6g_project_bn False\n","block6g_drop False\n","block6g_add False\n","block6h_expand_conv False\n","block6h_expand_bn False\n","block6h_expand_activation False\n","block6h_dwconv False\n","block6h_bn False\n","block6h_activation False\n","block6h_se_squeeze False\n","block6h_se_reshape False\n","block6h_se_reduce False\n","block6h_se_expand False\n","block6h_se_excite False\n","block6h_project_conv False\n","block6h_project_bn False\n","block6h_drop False\n","block6h_add False\n","block7a_expand_conv False\n","block7a_expand_bn False\n","block7a_expand_activation False\n","block7a_dwconv False\n","block7a_bn False\n","block7a_activation False\n","block7a_se_squeeze False\n","block7a_se_reshape False\n","block7a_se_reduce False\n","block7a_se_expand False\n","block7a_se_excite False\n","block7a_project_conv False\n","block7a_project_bn False\n","block7b_expand_conv False\n","block7b_expand_bn False\n","block7b_expand_activation False\n","block7b_dwconv False\n","block7b_bn False\n","block7b_activation False\n","block7b_se_squeeze False\n","block7b_se_reshape False\n","block7b_se_reduce False\n","block7b_se_expand False\n","block7b_se_excite False\n","block7b_project_conv True\n","block7b_project_bn True\n","block7b_drop True\n","block7b_add True\n","top_conv True\n","top_bn True\n","top_activation True\n"]}],"source":["for layer in base_model.layers:\n","  print(layer.name,layer.trainable)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y3RX05i2nFvI","outputId":"612b7958-06a6-4639-9c8a-e46852a369cf","executionInfo":{"status":"ok","timestamp":1699451409861,"user_tz":-120,"elapsed":776663,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Saving TensorBoard log files to: FOOD_VISION_101/Efficient_net_fine_tuned/20231108-133601\n","Epoch 4/6\n","2367/2368 [============================>.] - ETA: 0s - loss: 1.0505 - accuracy: 0.7203"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2368/2368 [==============================] - 255s 100ms/step - loss: 1.0505 - accuracy: 0.7203 - val_loss: 1.0909 - val_accuracy: 0.7035\n","Epoch 5/6\n","2367/2368 [============================>.] - ETA: 0s - loss: 0.9745 - accuracy: 0.7391"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2368/2368 [==============================] - 238s 100ms/step - loss: 0.9745 - accuracy: 0.7392 - val_loss: 1.0899 - val_accuracy: 0.7015\n","Epoch 6/6\n","2367/2368 [============================>.] - ETA: 0s - loss: 0.9150 - accuracy: 0.7556"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2368/2368 [==============================] - 243s 102ms/step - loss: 0.9150 - accuracy: 0.7556 - val_loss: 1.0789 - val_accuracy: 0.7084\n"]}],"source":["model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n","              metrics=['accuracy'])\n","history_fine = model.fit(\n","    train_data,\n","    epochs=6,\n","    steps_per_epoch=len(train_data),\n","    validation_data=test_data,\n","    validation_steps=int(0.12*len(test_data)),\n","    initial_epoch=3,\n","    callbacks=[model_checkpoint,\n","               create_tensorboard_callback(\n","                  'FOOD_VISION_101',\n","                  'Efficient_net_fine_tuned'\n","               )]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"et0_4Ymhnha8","executionInfo":{"status":"aborted","timestamp":1699449045444,"user_tz":-120,"elapsed":10,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"}}},"outputs":[],"source":["base_model.trainable = True\n","for layer in base_model.layers[:5]:\n","  print(layer.name,layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1699449045444,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"},"user_tz":-120},"id":"rfXv61S3qDrK"},"outputs":[],"source":["model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n","              metrics=['accuracy'])\n","history_fine_all = model.fit(\n","    train_data,\n","    epochs=101,\n","    steps_per_epoch=len(train_data),\n","    validation_data=test_data,\n","    validation_steps=int(0.12*len(test_data)),\n","    callbacks=[model_checkpoint,\n","               create_tensorboard_callback(\n","                  'FOOD_VISION_101',\n","                  'Efficient_net_fine_tuned'\n","               )]\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"bWGsWPkhqb9T","colab":{"base_uri":"https://localhost:8080/","height":459},"executionInfo":{"status":"error","timestamp":1699449690334,"user_tz":-120,"elapsed":478921,"user":{"displayName":"Ashraf Aaref","userId":"15027702911304226078"}},"outputId":"d067082a-1464-49d5-d1c2-adde52818773"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/101\n","2368/2368 [==============================] - 459s 173ms/step - loss: 1.6598 - accuracy: 0.5766 - val_loss: 1.0612 - val_accuracy: 0.7074\n","Epoch 2/101\n","  60/2368 [..............................] - ETA: 6:37 - loss: 1.1799 - accuracy: 0.6979"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-f9c84769f3cf>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from tensorflow.keras import layers\n","from tensorflow.keras import preprocessing\n","\n","\n","base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n","base_model.trainable = True\n","\n","inputs = layers.Input(shape=(224, 224, 3),\n","                      name = 'input_layer')\n","\n","x = base_model(inputs)\n","\n","x = layers.GlobalAveragePooling2D(name='avg_pooling')(x)\n","\n","outputs = layers.Dense(101,\n","                       activation= 'softmax',\n","                       dtype=tf.float32)(x)\n","\n","model = tf.keras.Model(inputs,outputs)\n","\n","model.compile(\n","    loss= tf.keras.losses.SparseCategoricalCrossentropy(),\n","    optimizer= tf.keras.optimizers.Adam(),\n","    metrics=['accuracy']\n","    )\n","\n","history = model.fit(\n","    train_data,\n","    epochs=101,\n","    steps_per_epoch=len(train_data),\n","    validation_data=test_data,\n","    validation_steps=int(0.12*len(test_data)),\n",")"]},{"cell_type":"code","source":[],"metadata":{"id":"bzUpAHwBD1dk"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyNvAKvaf76JNJ2tFAKRFkKB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}